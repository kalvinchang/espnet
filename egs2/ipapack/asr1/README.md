# IPAPack

Phoneme recognition is a common task in speech benchmarks (e.g. SUPERB), as one desideratum of speech models is to learn basic pronunciation units. TIMIT is one of the most famous datasets for phoneme recognition. However, TIMIT only includes American English.

This recipe targets IPAPack [1], which provides one of the largest multilingual phonemically transcribed datasets (aside from the CMU Wilderness dataset - 14000 hours across 700 languages), with 1,000 hours of speech across 115 languages. 

IPAPack is derived from:
* FLEURS [2] - "the speech version of the FLoRes machine translation benchmark"
    * Creative Commons license
* DoReCo [3] - speech across 50 endangered languages from language documentation archives (44 languages in IPAPack)
    * Creative Commons license
    * [1] put the languages with a Creative Commons Non-Commercial license in the test set.
    * As required, we cite each constituent dataset within DoReCo.
* MSWC (Multilingual Spoken Word Corpus) [4] - clips of single words padded to 1 second derived with forced alignment from Mozilla Common Voice across 50 languages (36 in IPAPack)
    * Creative Commons license

As such, this recipe contains three test sets: `test_fleurs`, `test_doreco`, and `test_mswc`
We followed [1]'s original train/dev/test splits exactly.
There are at least five unseen languages in the test set: Vietnamese, Tamil, Hausa, Georgian, and Odia.

The dataset uses IPA for phonemic transcriptions (as opposed to ARPAbet) and did not perform normalization (see "Phoneme tokenizer" in [1]). However, all phonemes in the training data are supported by panphon / epitran.

Note: a 20,000 hour will be released soon, with consistent and clean Unicode tokenization of IPA symbols. 


In the results below, we can interpret the WER as phoneme error rate, because each phoneme is its own word after preprocessing the transcriptions.

<!-- Generated by scripts/utils/show_asr_result.sh -->
# RESULTS
## Environments
- date: `Mon Nov 25 23:30:12 EST 2024`
- python version: `3.9.20 | packaged by conda-forge | (main, Sep 22 2024, 14:11:32)  [GCC 13.3.0]`
- espnet version: `espnet 202402`
- pytorch version: `pytorch 2.3.0+cu121`
- Git hash: `6eadc31daa4e2bd8b3f02bab8c57dd4d539d9f23`
  - Commit date: `Sun Nov 24 23:12:44 2024 -0500`

## exp/asr_train_asr_transformer_raw_word
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test_doreco|5093|194760|53.9|34.4|11.8|4.7|50.9|100.0|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test_doreco|5093|396745|70.3|17.5|12.2|3.3|33.0|100.0|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|



# References

[1] Jian Zhu, Changbing Yang, Farhan Samir, and Jahurul Islam. 2024. The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language. In *Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies* (Volume 1: Long Papers), pages 750–772, Mexico City, Mexico. Association for Computational Linguistics.

[2] Alexis Conneau, Min Ma, Simran Khanuja, Yu Zhang, Vera Axelrod, Siddharth Dalmia, Jason Riesa, Clara Rivera, and Ankur Bapna. 2022. FLEURS: Few-shot learning evaluation of universal representations of speech. In *2022 IEEE Spoken Language Technology Workshop* (SLT), pp. 798-805. IEEE.

[3] Ludger Paschen, François Delafontaine, Christoph Draxler, Susanne Fuchs, Matthew Stave, and Frank Seifart. 2020. Building a Time-Aligned Cross-Linguistic Reference Corpus from Language Documentation Data (DoReCo). In *Proceedings of the Twelfth Language Resources and Evaluation Conference*, pages 2657–2666, Marseille, France. European Language Resources Association.

[4] Mark Mazumder, Sharad Chitlangia, Colby Banbury, Yiping Kang, Juan Manuel Ciro, Keith Achorn, Daniel Galvez et al. 2021. Multilingual spoken words corpus. In *Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track* (Round 2).

[5] Mathieu Avanzi, Marie-José Béguelin, Gilles Corminboeuf, Federica Diémoz, and Laure Anne Johnsen. 2022. French (Swiss) DoReCo dataset. In Frank Seifart, Ludger Paschen, and Matthew Stave, editors, Language Documentation Reference Corpus (DoReCo) 1.2. Leibniz-Zentrum Allgemeine Sprachwissenschaft & laboratoire Dynamique Du Langage (UMR5596, CNRS & Université Lyon 2), Berlin & Lyon.
